{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Run Anima on Google Colab via ComfyUI\n",
        "* ðŸ¤— [Anima Model On Hugging Face](https://huggingface.co/circlestone-labs/Anima)\n",
        "* ðŸ“„ **License**: Provided under the [circlestone-labs-non-commercial-license\n",
        "](https://huggingface.co/circlestone-labs/Anima/blob/main/LICENSE.md)"
      ],
      "metadata": {
        "id": "R8cp3cdjC1-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install ComfyUI and Download Model\n",
        "!apt -q install -y aria2\n",
        "%cd /content/\n",
        "!git clone https://github.com/comfyanonymous/ComfyUI\n",
        "%cd /content/ComfyUI\n",
        "!pip -q install -r requirements.txt\n",
        "%cd /content/ComfyUI/custom_nodes\n",
        "!git clone https://github.com/ltdrdata/ComfyUI-Manager.git || true\n",
        "%cd /content/ComfyUI/custom_nodes/ComfyUI-Manager\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "\n",
        "\n",
        "!aria2c -c -x16 -s16 -k1M https://huggingface.co/circlestone-labs/Anima/resolve/main/split_files/diffusion_models/anima-preview.safetensors \\\n",
        "-d /content/ComfyUI/models/diffusion_models -o anima-preview.safetensors > /dev/null 2>&1 \\\n",
        "&& echo \"âœ… Diffusion model download complete\" || echo \"âŒ Diffusion model download failed\"\n",
        "\n",
        "!aria2c -c -x16 -s16 -k1M https://huggingface.co/pachiiahri/anima-fp8-comfyui/resolve/main/anima-preview_tcfp8_mixed.safetensors \\\n",
        "-d /content/ComfyUI/models/diffusion_models -o anima-preview_tcfp8_mixed.safetensors > /dev/null 2>&1 \\\n",
        "&& echo \"âœ… fp8 Diffusion model download complete\" || echo \"âŒ fp8 Diffusion model download failed\"\n",
        "\n",
        "!aria2c -c -x16 -s16 -k1M https://huggingface.co/circlestone-labs/Anima/resolve/main/split_files/text_encoders/qwen_3_06b_base.safetensors \\\n",
        "-d /content/ComfyUI/models/text_encoders -o qwen_3_06b_base.safetensors > /dev/null 2>&1 \\\n",
        "&& echo \"âœ… Text encoder download complete\" || echo \"âŒ Text encoder download failed\"\n",
        "\n",
        "!aria2c -c -x16 -s16 -k1M https://huggingface.co/circlestone-labs/Anima/resolve/main/split_files/vae/qwen_image_vae.safetensors \\\n",
        "-d /content/ComfyUI/models/vae -o qwen_image_vae.safetensors > /dev/null 2>&1 \\\n",
        "&& echo \"âœ… VAE download complete\" || echo \"âŒ VAE download failed\"\n",
        "import requests, json, os\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/NeuralFalconYT/comfyUI_Colab/refs/heads/main/workflow/anima.json\"\n",
        "\n",
        "save_path = \"/content/ComfyUI/user/default/workflows\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "data = requests.get(url).json()\n",
        "\n",
        "with open(f\"{save_path}/anima.json\", \"w\") as f:\n",
        "    json.dump(data, f, indent=2)\n",
        "\n",
        "print(\"âœ… Workflow set as default\")\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "from IPython.display import Audio,display\n",
        "display(Audio(\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\", autoplay=True))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9jchdiPMQDOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RW4ebTL5O9M_"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Run Comfy UI\n",
        "%cd /content\n",
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i cloudflared-linux-amd64.deb >/dev/null 2>&1 || true\n",
        "\n",
        "import subprocess, re,time ,socket,threading\n",
        "\n",
        "def tunnel_printer(port):\n",
        "    while True:\n",
        "        time.sleep(0.5)\n",
        "        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "        try:\n",
        "            if s.connect_ex((\"127.0.0.1\", port)) == 0:\n",
        "                break\n",
        "        finally:\n",
        "            s.close()\n",
        "    print(\"\\nComfyUI is up. Launching cloudflared tunnel...\")\n",
        "    p = subprocess.Popen(\n",
        "        [\"cloudflared\", \"tunnel\", \"--url\", f\"http://127.0.0.1:{port}\"],\n",
        "        stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True\n",
        "    )\n",
        "    for line in p.stderr:\n",
        "        if \"trycloudflare.com\" in line:\n",
        "            url = re.findall(r\"https?://[^\\s]+trycloudflare\\.com[^\\s]*\", line)\n",
        "            if url:\n",
        "                print(\"\\nðŸ”— Access ComfyUI:\", url[0])\n",
        "\n",
        "%cd /content/ComfyUI\n",
        "PORT=8188\n",
        "threading.Thread(target=tunnel_printer, args=(PORT,), daemon=True).start()\n",
        "\n",
        "print(\"\\nStarting ComfyUI...\")\n",
        "!python main.py --listen 0.0.0.0 --port {PORT} --dont-print-server\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run Gradio UI [Run 2 times first Error second Run]\n",
        "%cd /content/ComfyUI\n",
        "import os, sys, importlib\n",
        "\n",
        "# ---- Fix utils shadowing issue ----\n",
        "if \"utils\" in sys.modules:\n",
        "    del sys.modules[\"utils\"]\n",
        "\n",
        "importlib.invalidate_caches()\n",
        "\n",
        "curr_dir=os.getcwd()\n",
        "sys.path.insert(0,curr_dir)\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# Imports\n",
        "# ==========================================================\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# Helper function\n",
        "# ==========================================================\n",
        "def get_value_at_index(obj, index):\n",
        "    try:\n",
        "        return obj[index]\n",
        "    except KeyError:\n",
        "        return obj[\"result\"][index]\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# Initialize ComfyUI backend properly\n",
        "# ==========================================================\n",
        "def import_custom_nodes():\n",
        "    import asyncio\n",
        "    import execution\n",
        "    import server\n",
        "    from nodes import init_extra_nodes\n",
        "\n",
        "    loop = asyncio.new_event_loop()\n",
        "    asyncio.set_event_loop(loop)\n",
        "\n",
        "    prompt_server = server.PromptServer(loop)\n",
        "    execution.PromptQueue(prompt_server)\n",
        "\n",
        "    init_extra_nodes()\n",
        "\n",
        "\n",
        "# Import node mapping AFTER path fixes\n",
        "from nodes import NODE_CLASS_MAPPINGS\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# MODEL CACHE (LOAD ONCE)\n",
        "# ==========================================================\n",
        "MODEL_CACHE = {}\n",
        "\n",
        "\n",
        "def load_models_once():\n",
        "    if MODEL_CACHE:\n",
        "        return MODEL_CACHE\n",
        "\n",
        "    print(\"ðŸš€ Loading ComfyUI models (first time only)...\")\n",
        "\n",
        "    import_custom_nodes()\n",
        "\n",
        "    # CLIP text encoder\n",
        "    cliploader = NODE_CLASS_MAPPINGS[\"CLIPLoader\"]()\n",
        "    clip = cliploader.load_clip(\n",
        "        clip_name=\"qwen_3_06b_base.safetensors\",\n",
        "        type=\"stable_diffusion\",\n",
        "        device=\"default\",\n",
        "    )\n",
        "\n",
        "    # VAE\n",
        "    vaeloader = NODE_CLASS_MAPPINGS[\"VAELoader\"]()\n",
        "    vae = vaeloader.load_vae(\"qwen_image_vae.safetensors\")\n",
        "\n",
        "    # Full diffusion model (no quantization)\n",
        "    unetloader = NODE_CLASS_MAPPINGS[\"UNETLoader\"]()\n",
        "    model = unetloader.load_unet(\n",
        "        unet_name=\"anima-preview.safetensors\",\n",
        "        weight_dtype=\"default\",\n",
        "    )\n",
        "\n",
        "    MODEL_CACHE.update({\n",
        "        \"clip\": clip,\n",
        "        \"vae\": vae,\n",
        "        \"model\": model,\n",
        "    })\n",
        "\n",
        "    print(\"âœ… Models loaded successfully.\")\n",
        "    return MODEL_CACHE\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# IMAGE GENERATION FUNCTION\n",
        "# ==========================================================\n",
        "OUTPUT_DIR = \"./outputs\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "def generate_image(\n",
        "    positive_prompt,\n",
        "    negative_prompt=\"\",\n",
        "    width=1024,\n",
        "    height=1024,\n",
        "    steps=30,\n",
        "    cfg=4,\n",
        "):\n",
        "\n",
        "    models = load_models_once()\n",
        "\n",
        "    clip = models[\"clip\"]\n",
        "    vae = models[\"vae\"]\n",
        "    model = models[\"model\"]\n",
        "\n",
        "    with torch.inference_mode():\n",
        "\n",
        "        # Encode prompts\n",
        "        clipencode = NODE_CLASS_MAPPINGS[\"CLIPTextEncode\"]()\n",
        "\n",
        "        pos = clipencode.encode(\n",
        "            text=positive_prompt,\n",
        "            clip=get_value_at_index(clip, 0),\n",
        "        )\n",
        "\n",
        "        neg = clipencode.encode(\n",
        "            text=negative_prompt,\n",
        "            clip=get_value_at_index(clip, 0),\n",
        "        )\n",
        "\n",
        "        # Create latent image\n",
        "        latentnode = NODE_CLASS_MAPPINGS[\"EmptyLatentImage\"]()\n",
        "        latent = latentnode.generate(\n",
        "            width=width,\n",
        "            height=height,\n",
        "            batch_size=1,\n",
        "        )\n",
        "\n",
        "        # Sampling\n",
        "        sampler = NODE_CLASS_MAPPINGS[\"KSampler\"]()\n",
        "        samples = sampler.sample(\n",
        "            seed=random.randint(1, 2**64),\n",
        "            steps=steps,\n",
        "            cfg=cfg,\n",
        "            sampler_name=\"euler\",\n",
        "            scheduler=\"simple\",\n",
        "            denoise=1,\n",
        "            model=get_value_at_index(model, 0),\n",
        "            positive=get_value_at_index(pos, 0),\n",
        "            negative=get_value_at_index(neg, 0),\n",
        "            latent_image=get_value_at_index(latent, 0),\n",
        "        )\n",
        "\n",
        "        # Decode image\n",
        "        decode = NODE_CLASS_MAPPINGS[\"VAEDecode\"]()\n",
        "        decoded = decode.decode(\n",
        "            samples=get_value_at_index(samples, 0),\n",
        "            vae=get_value_at_index(vae, 0),\n",
        "        )\n",
        "\n",
        "        # Convert tensor â†’ image\n",
        "        img_tensor = get_value_at_index(decoded, 0)[0]\n",
        "        img = Image.fromarray(\n",
        "            np.clip(img_tensor.cpu().numpy() * 255, 0, 255).astype(np.uint8)\n",
        "        )\n",
        "\n",
        "        # Save image\n",
        "        path = os.path.join(\n",
        "            OUTPUT_DIR,\n",
        "            f\"anima_{random.randint(1000,9999)}.png\"\n",
        "        )\n",
        "        img.save(path)\n",
        "\n",
        "        return path\n",
        "\n",
        "\n",
        "load_models_once()\n",
        "\n",
        "\n",
        "# img_path = generate_image(\n",
        "#     positive_prompt=\"masterpiece anime girl portrait, cinematic lighting\",\n",
        "#     negative_prompt=\"low quality, blurry\",\n",
        "# )\n",
        "\n",
        "# print(\"ðŸŽ‰ Generated image:\", img_path)\n",
        "\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "\n",
        "def ui_generate(pos, neg, w, h, steps, cfg):\n",
        "    path = generate_image(\n",
        "        positive_prompt=pos,\n",
        "        negative_prompt=neg,\n",
        "        width=w,\n",
        "        height=h,\n",
        "        steps=steps,\n",
        "        cfg=cfg,\n",
        "    )\n",
        "    return path\n",
        "\n",
        "css=\"\"\"\n",
        "  .gradio-container\n",
        "  { font-family: 'SF Pro Display', -apple-system, BlinkMacSystemFont, sans-serif; }\n",
        "  \"\"\"\n",
        "with gr.Blocks(theme=gr.themes.Soft(),css=css) as demo:\n",
        "    gr.HTML(\"\"\"\n",
        "          <div style=\"text-align: center; margin: 20px auto; max-width: 800px;\">\n",
        "              <h1 style=\"font-size: 2.5em; margin-bottom: 5px;\">Anima</h1>\n",
        "          </div>\"\"\")\n",
        "    with gr.Row():\n",
        "\n",
        "        # LEFT SIDE\n",
        "        with gr.Column(scale=1):\n",
        "            pos_prompt = gr.Textbox(\n",
        "                label=\"Positive Prompt\",\n",
        "                placeholder=\"Enter positive prompt...\",\n",
        "                lines=4,\n",
        "            )\n",
        "\n",
        "            neg_prompt = gr.Textbox(\n",
        "                label=\"Negative Prompt\",\n",
        "                placeholder=\"Enter negative prompt...\",\n",
        "                lines=2,\n",
        "            )\n",
        "\n",
        "            generate_btn = gr.Button(\"Generate Image\", variant=\"primary\")\n",
        "\n",
        "            # Hidden advanced settings\n",
        "            with gr.Accordion(\"Advanced Settings\", open=False):\n",
        "                width = gr.Slider(256, 1536, 1024, step=64, label=\"Width\")\n",
        "                height = gr.Slider(256, 1536, 1024, step=64, label=\"Height\")\n",
        "                steps = gr.Slider(10, 60, 30, step=1, label=\"Steps\")\n",
        "                cfg = gr.Slider(1, 10, 4, step=0.5, label=\"CFG\")\n",
        "\n",
        "        # RIGHT SIDE\n",
        "        with gr.Column(scale=1):\n",
        "            output_img = gr.Image(label=\"Generated Image\")\n",
        "\n",
        "    generate_btn.click(\n",
        "        fn=ui_generate,\n",
        "        inputs=[pos_prompt, neg_prompt, width, height, steps, cfg],\n",
        "        outputs=output_img,\n",
        "    )\n",
        "\n",
        "\n",
        "demo.launch(share=True,debug=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PbIB6EU_Hvy9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}